{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# check python version\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DH\\projects\\Bangkit-C22CB-Company-Based-Capstone\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers and tensorflow are installed\n"
     ]
    }
   ],
   "source": [
    "# check if transformers and tensorflow are installed, if not install them\n",
    "# use transformers version 4.18.0 and tensorflow version 2.8.0\n",
    "try:\n",
    "    import transformers\n",
    "    import tensorflow as tf\n",
    "    print(\"transformers and tensorflow are installed\")\n",
    "except:\n",
    "    print(\"transformers and tensorflow are not installed\")\n",
    "    print(\"installing transformers and tensorflow\")\n",
    "    import subprocess\n",
    "    subprocess.call(['pip', 'install', 'transformers==4.18.0'])\n",
    "    subprocess.call(['pip', 'install', 'tensorflow==2.8.0'])\n",
    "    import transformers\n",
    "    import tensorflow as tf\n",
    "    print(\"transformers and tensorflow are installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at Andaf/bert-uncased-finetuned-squad-indonesian.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import TFAutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Andaf/bert-uncased-finetuned-squad-indonesian\")\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"Andaf/bert-uncased-finetuned-squad-indonesian\", return_dict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sisa kamar hotel: 12.\n",
      "\n",
      "Kondisi hotel bersih, ruang resepsionis tidak ramai.\n",
      "\n",
      "Pembayaran dapat dilakukan melalui transfer bank atau membayar melalui minimarket.\n",
      "\n",
      "Penjadwalan ulang flight booking dapat dilakukan dengan mengirim email.\n",
      "\n",
      "Kirim email ke customer-service@traveloka.com \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open context.txt file\n",
    "with open(\"context_id.txt\", \"r\") as f:\n",
    "    file = f.read()\n",
    "\n",
    "context = file\n",
    "\n",
    "print(context, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'bagaimana kondisi ruang respsionis?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tidak ramai \n",
      "\n",
      "0.020230732858181 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = nlp(\n",
    "    question = question,\n",
    "    context = context\n",
    ")\n",
    "\n",
    "answer = result['answer']\n",
    "confidence = result['score']\n",
    "print(answer, '\\n')\n",
    "print(confidence, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make requirements.txt\n",
    "# !pip freeze > ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7f8b4dcb172d5ee7cbc6306f910f9536d12fce62ed018c909e0bf052dc4ebfc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
