{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# check python version\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.18.0 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (4.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: sacremoses in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (0.0.49)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (0.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (21.3)\n",
      "Requirement already satisfied: requests in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (1.22.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (0.12.1)\n",
      "Requirement already satisfied: filelock in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from transformers==4.18.0) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from packaging>=20.0->transformers==4.18.0) (3.0.8)\n",
      "Requirement already satisfied: colorama in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from tqdm>=4.27->transformers==4.18.0) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from requests->transformers==4.18.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from requests->transformers==4.18.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from requests->transformers==4.18.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from requests->transformers==4.18.0) (2.0.12)\n",
      "Requirement already satisfied: joblib in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from sacremoses->transformers==4.18.0) (1.1.0)\n",
      "Requirement already satisfied: click in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from sacremoses->transformers==4.18.0) (8.1.2)\n",
      "Requirement already satisfied: six in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from sacremoses->transformers==4.18.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install transformers 4.18.0, for colab\n",
    "%pip install transformers==4.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DH\\projects\\Bangkit-C22CB-Company-Based-Capstone\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers and tensorflow are installed\n"
     ]
    }
   ],
   "source": [
    "# check if transformers and tensorflow are installed, if not install them\n",
    "# use transformers version 4.18.0 and tensorflow version 2.8.0\n",
    "try:\n",
    "    import transformers\n",
    "    import tensorflow as tf\n",
    "    print(\"transformers and tensorflow are installed\")\n",
    "except:\n",
    "    print(\"transformers and tensorflow are not installed\")\n",
    "    print(\"installing transformers and tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at cahya/bert-base-indonesian-522M were not used when initializing TFBertModel: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at cahya/bert-base-indonesian-522M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cahya/bert-base-indonesian-522M\"\n",
    "batch_size = 32\n",
    "\n",
    "from transformers import BertTokenizer, TFAutoModel # make sure use tensorflow model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  110617344 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,617,344\n",
      "Trainable params: 110,617,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3, 1769, 8343, 6186, 32, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test tokenizer\n",
    "tokenizer(\"Nama kamu siapa?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3, 3245, 5366, 2464, 6014, 11186, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"saya suka makan nasi goreng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at cahya/bert-base-indonesian-522M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0840364545583725,\n",
       "  'token': 2186,\n",
       "  'token_str': 'berada',\n",
       "  'sequence': 'mainan saya berada di jalan'},\n",
       " {'score': 0.07038316130638123,\n",
       "  'token': 1821,\n",
       "  'token_str': 'ada',\n",
       "  'sequence': 'mainan saya ada di jalan'},\n",
       " {'score': 0.0403575636446476,\n",
       "  'token': 1998,\n",
       "  'token_str': 'sendiri',\n",
       "  'sequence': 'mainan saya sendiri di jalan'},\n",
       " {'score': 0.029048316180706024,\n",
       "  'token': 2444,\n",
       "  'token_str': 'lahir',\n",
       "  'sequence': 'mainan saya lahir di jalan'},\n",
       " {'score': 0.028137197718024254,\n",
       "  'token': 3812,\n",
       "  'token_str': 'berdiri',\n",
       "  'sequence': 'mainan saya berdiri di jalan'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = transformers.pipeline('fill-mask', model = model_name)\n",
    "unmasker(\"mainan saya [MASK] di jalan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (1.4.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\dh\\projects\\bangkit-c22cb-company-based-capstone\\venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset json file\n",
    "import json\n",
    "\n",
    "# uncomment this if you use local machine\n",
    "train_json_dir = \"Translated/train-v2.0_indo.json\"\n",
    "dev_json_dir = \"Translated/dev-v2.0_indo.json\"\n",
    "tester_json_dir  = \"Translated/tester_indo.json\"\n",
    "\n",
    "# uncomment this if you use google colab\n",
    "# train_json_dir = \"/content/train-v2.0_indo.json\"\n",
    "# dev_json_dir = \"/content/dev-v2.0_indo.json\"\n",
    "# tester_json_dir  = \"/content/tester_indo.json\"\n",
    "\n",
    "dataset_dirs = [train_json_dir, dev_json_dir, tester_json_dir]\n",
    "# dataset_dirs = [tester_json_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This function is for converting SQuAD json file to pandas dataframe, iteratively\n",
    "\n",
    "    I dont want run this locally, better use colab\n",
    "'''\n",
    "\n",
    "import utils\n",
    "\n",
    "for dir in dataset_dirs:\n",
    "    with open(dir, encoding=\"utf-8\") as json_file:\n",
    "        file = json.load(json_file)\n",
    "        dict_file = file\n",
    "        data = dict_file['data']\n",
    "\n",
    "    df = utils.json_to_df(data)\n",
    "    df.to_csv(dir.replace(\".json\", \".csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384  # The maximum length of a feature (question and context)\n",
    "doc_stride = 128  # The allowed overlap between two part of the context when splitting is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orang Normandia</td>\n",
       "      <td>Bangsa Norman (Norman: Nourmands; Prancis: Nor...</td>\n",
       "      <td>Di negara manakah Normandia berada?</td>\n",
       "      <td>Perancis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orang Normandia</td>\n",
       "      <td>Bangsa Norman (Norman: Nourmands; Prancis: Nor...</td>\n",
       "      <td>Di negara manakah Normandia berada?</td>\n",
       "      <td>Perancis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orang Normandia</td>\n",
       "      <td>Bangsa Norman (Norman: Nourmands; Prancis: Nor...</td>\n",
       "      <td>Di negara manakah Normandia berada?</td>\n",
       "      <td>Perancis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orang Normandia</td>\n",
       "      <td>Bangsa Norman (Norman: Nourmands; Prancis: Nor...</td>\n",
       "      <td>Di negara manakah Normandia berada?</td>\n",
       "      <td>Perancis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orang Normandia</td>\n",
       "      <td>Bangsa Norman (Norman: Nourmands; Prancis: Nor...</td>\n",
       "      <td>Kapan orang Normandia di Normandia?</td>\n",
       "      <td>abad 10 dan 11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title                                            context  \\\n",
       "0  orang Normandia  Bangsa Norman (Norman: Nourmands; Prancis: Nor...   \n",
       "1  orang Normandia  Bangsa Norman (Norman: Nourmands; Prancis: Nor...   \n",
       "2  orang Normandia  Bangsa Norman (Norman: Nourmands; Prancis: Nor...   \n",
       "3  orang Normandia  Bangsa Norman (Norman: Nourmands; Prancis: Nor...   \n",
       "4  orang Normandia  Bangsa Norman (Norman: Nourmands; Prancis: Nor...   \n",
       "\n",
       "                              question          answer  \n",
       "0  Di negara manakah Normandia berada?        Perancis  \n",
       "1  Di negara manakah Normandia berada?        Perancis  \n",
       "2  Di negara manakah Normandia berada?        Perancis  \n",
       "3  Di negara manakah Normandia berada?        Perancis  \n",
       "4  Kapan orang Normandia di Normandia?  abad 10 dan 11  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tester_csv_dir = \"Translated/tester_indo.csv\"\n",
    "\n",
    "# open all csv file\n",
    "df_tester = pd.read_csv(tester_csv_dir)\n",
    "df_tester.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7f8b4dcb172d5ee7cbc6306f910f9536d12fce62ed018c909e0bf052dc4ebfc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
